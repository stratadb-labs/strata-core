# v0.4: Vector Enhancements

**Theme**: Vector search at scale.

v0.1 ships brute-force vector search, which is correct but O(n) per query. v0.4 adds approximate nearest neighbor indexing and storage optimizations to handle larger vector collections.

## Features

### HNSW Index Backend

Add Hierarchical Navigable Small World graph indexing for sub-linear vector search.

- `IndexBackendFactory` trait already exists in `crates/engine/src/primitives/vector/`
- `VectorIndexBackend` trait defines the interface: `insert`, `remove`, `search`, `len`
- `BruteForceBackend` is the current implementation
- Add `HnswBackend` as a new backend, selectable per collection at creation time
- Consider wrapping an existing HNSW library (e.g., `instant-distance` or `hnsw_rs`)

### F16 Half-Precision Storage

Store vectors in 16-bit floating point to halve memory usage.

- `StorageDtype` enum in `crates/core/src/primitives/vector.rs` already reserves byte value `1` for F16
- Currently only `F32` (value `0`) is implemented
- Add conversion between F32 (compute) and F16 (storage)
- Quantization happens at storage time; search uses F32 internally

### Int8 Scalar Quantization

Store vectors as 8-bit integers for 4x memory reduction vs F32.

- `StorageDtype` reserves byte value `2` for Int8
- Requires calibration step to determine scale/offset per collection
- Higher compression, lower accuracy -- suitable for large-scale retrieval

### Advanced Metadata Filters

Extend metadata filtering beyond simple equality.

- `MetadataFilter` type exists in `crates/core/src/primitives/vector.rs`
- `JsonScalar` supports basic scalar types
- Add: range filters (`gt`, `lt`, `gte`, `lte`), `in` operator, nested path access
- Filters applied during search to prune candidates before distance computation

### Batch Vector Upsert

Insert/update multiple vectors in a single operation.

- Currently each upsert is a separate command
- Batch API reduces transaction overhead for bulk ingestion
- Important for RAG pipelines that embed documents in chunks

### Collection Statistics

Expose per-collection metrics.

- Add: vector count, dimension, index type, storage size, dtype distribution
- Useful for monitoring and capacity planning

## Context

Vector search is central to AI agent workloads (RAG, memory retrieval, similarity matching). Brute-force works for <10K vectors but real applications often need 100K+. Index backends and quantization unlock these scales.

## Dependencies

None -- builds on v0.1 vector infrastructure.
